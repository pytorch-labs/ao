{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from functools import reduce\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile\n",
    "def unpack(data, data_size) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Unpacks small dtype elements from a larger dtype.\n",
    "    \n",
    "    Inputs:\n",
    "    data: torch.Tensor - a tensor of packed elements of a small dtype within a larger dtype.\n",
    "    data_size: int - the size of the small dtype in bits.\n",
    "    \n",
    "    Returns: torch.Tensor - a tensor of the unpacked elements.\n",
    "    \"\"\"\n",
    "    shape = data.shape\n",
    "    scale = data.element_size() * 8 // data_size\n",
    "    unpacked_data = []\n",
    "    for i in range(scale):\n",
    "        shift_amt = data.element_size() * 8 - data_size * (i + 1) # how much to shift to get the ith uint\n",
    "        nbits = (1 << data_size) - 1 # mask for the last dtype_size bits\n",
    "        unpacked_data.append(((data >> shift_amt) & (nbits)).to(data.dtype))\n",
    "    return torch.stack(unpacked_data,dim=-1).view(up_size(shape, scale)) # stack the unpacked data and reshape to the original shape\n",
    "\n",
    "@torch.compile\n",
    "def pack(data, container_size, data_size) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Packs small dtype elements into a larger dtype.\n",
    "    \n",
    "    Inputs:\n",
    "    data: torch.Tensor - a tensor of unpacked elements of a small dtype.\n",
    "    container_size: int - the size of the large dtype in bits.\n",
    "    data_size: int - the size of the small dtype in bits.\n",
    "    \n",
    "    Returns: torch.Tensor - a tensor of the packed elements.\n",
    "    \"\"\"\n",
    "    scale = container_size // data_size\n",
    "    assert scale > 1, f\"container_size ({container_size}) not double the capacity ofdata_size ({data_size})\"\n",
    "    # pad the data to be divisible by scale\n",
    "    if data.shape[-1] % scale != 0:\n",
    "        padding = torch.zeros((*data.shape[:-1], scale - data.shape[-1] % scale), dtype=data.dtype)\n",
    "        data = torch.cat([data, padding], dim=-1)\n",
    "    \n",
    "    shape = data.shape\n",
    "    data = data.contiguous().view(-1)\n",
    "    #shift the data to the different indexes within the larger dtype and then union them together\n",
    "    ret = reduce(lambda x,y: x|y,[data[i::scale] << container_size-data_size*(i+1) for i in range(scale)])\n",
    "    newshape = down_size(shape, scale)\n",
    "    return ret.view(newshape)\n",
    "\n",
    "def down_size(size, amt):\n",
    "    assert size[-1] % amt == 0, f\"{size} last dim not divisible by {amt}\"\n",
    "    return (*size[:-1], size[-1] // amt)\n",
    "\n",
    "\n",
    "def up_size(size, amt):\n",
    "    return (*size[:-1], size[-1] * amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch._dynamo.config.specialize_int = True\n",
    "os.environ[\"TORCH_LOGS\"] = \"output_code\"\n",
    "test_tensor = torch.randint(0, 15, (1, 1, 6), dtype=torch.uint8)\n",
    "packed = pack(test_tensor, 8, 4)\n",
    "unpacked = unpack(packed, 4)\n",
    "unpadded = unpacked[..., :test_tensor.shape[-1]]\n",
    "assert(unpadded.allclose(test_tensor))\n",
    "\n",
    "test_tensor = torch.randint(0, 7, (5,1, 4), dtype=torch.int16)\n",
    "packed = pack(test_tensor,16, 3)\n",
    "unpacked = unpack(packed, 3)\n",
    "unpadded = unpacked[..., :test_tensor.shape[-1]]\n",
    "assert(unpadded.allclose(test_tensor))\n",
    "\n",
    "test_tensor = torch.randint(0, 15, (3,1, 9), dtype=torch.int32)\n",
    "packed = pack(test_tensor,32, 16)\n",
    "unpacked = unpack(packed,16)\n",
    "unpadded = unpacked[..., :test_tensor.shape[-1]]\n",
    "assert(unpadded.allclose(test_tensor))\n",
    "\n",
    "test_tensor = torch.randint(0, 3, (8, 8, 7), dtype=torch.uint8)\n",
    "packed = pack(test_tensor, 8, 2)\n",
    "unpacked = unpack(packed,2)\n",
    "unpadded = unpacked[..., :test_tensor.shape[-1]]\n",
    "assert(unpadded.allclose(test_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
